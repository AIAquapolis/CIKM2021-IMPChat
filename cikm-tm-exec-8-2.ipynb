{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8931f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PBIN_DIR=/share_6/work/solepro-moriya/jupyter102/venv-3.9.10-cikm/bin\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "pbin_dir = os.path.dirname(sys.executable)\n",
    "%env PBIN_DIR={pbin_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98be73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!${PBIN_DIR}/pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941334e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!${PBIN_DIR}/pip uninstall -y torchtext\n",
    "#!${PBIN_DIR}/pip install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7529c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf ./dataset/reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31a4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7c1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#cd dataset\n",
    "#tar -jxvf reddit.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b408cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir dataset/reddit\n",
    "#!mv dataset/*_reddit.pkl dataset/reddit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ad34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp dataset/reddit/test_reddit.pkl dataset/reddit/dev_reddit.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83e0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#cd dataset\n",
    "#tar -jxvf reddit_emb.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43986259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp dataset/vocab_and_embeddings.pkl dataset/reddit/vocab_and_embeddings.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd34bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3cb9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!${PBIN_DIR}/pip install torchtext==0.9.1 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f00f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(task='reddit2', is_training=True, max_utterances=29, emb_len=200, max_words=50, gru_hidden=300, learning_rate=0.0005, l2_reg=0.0, epochs=100, save_path='./checkpoint/reddit2.IMPChat.2022-07-08_10:21:22.pt', score_file_path='./dataset/reddit2/score_file.txtIMPChat.2022-07-08_10:21:22', eval_steps=40000, batch_size=32, local_rank=-1, n_gpu=2, n_layer=3, use_cross_matching=True, n_filters=128, max_hop=2, exact_sigma=0.001, sigma=0.1, type_file='./dataset/reddit2/test.type', model_file_name='reddit2_impchat.pt')\n",
      "Task:  reddit2\n",
      "IMPChat(\n",
      "  (word_embedding): Embedding(164617, 200, padding_idx=0)\n",
      "  (selector_transformer): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (linear_word): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (linear_score): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transformer_r): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_rp): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_utt): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_res): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ur): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ru): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (cnn_2d_1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (affine2): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (affine3): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (gru_acc): GRU(200, 300, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (linear1): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (linear2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      "  (affine_out): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "X_utterances:  torch.Size([151910, 29, 50])\n",
      "X_responses:  torch.Size([151910, 50])\n",
      "y_labels:  torch.Size([151910])\n",
      "X_utterances:  torch.Size([177950, 29, 50])\n",
      "X_responses:  torch.Size([177950, 50])\n",
      "INFO:impchat:IMPChat(\n",
      "  (word_embedding): Embedding(164617, 200, padding_idx=0)\n",
      "  (selector_transformer): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (linear_word): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (linear_score): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transformer_r): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_rp): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_utt): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_res): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ur): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ru): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (cnn_2d_1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (affine2): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (affine3): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (gru_acc): GRU(200, 300, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (linear1): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (linear2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      "  (affine_out): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "INFO:impchat:Start to train...\n",
      "INFO:impchat:train set: 151910\n",
      "INFO:impchat:test set: 177950\n",
      "\n",
      "Epoch  1 / 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share_6/work/solepro-moriya/jupyter102/venv-3.9.10-cikm/lib/python3.9/site-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "Batch[0] - loss: 1.117074  batch_size:32\n",
      "Batch[500] - loss: 0.297251  batch_size:32\n",
      "Batch[1000] - loss: 0.341031  batch_size:32\n",
      "Batch[1500] - loss: 0.124260  batch_size:32\n",
      "Batch[2000] - loss: 0.426045  batch_size:32\n",
      "Batch[2500] - loss: 0.350152  batch_size:32\n",
      "Batch[3000] - loss: 0.323584  batch_size:32\n",
      "Batch[3500] - loss: 0.234431  batch_size:32\n",
      "Batch[4000] - loss: 0.382216  batch_size:32\n",
      "Batch[4500] - loss: 0.193359  batch_size:32\n",
      "Average loss:0.280599 \n",
      "5561it [03:35, 25.78it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6059656716484634\tMRR:0.6059656716484634\tP@1:0.4555774093846586\tR1:0.4555774093846586\tR2:0.582354593987075\tR5:0.8118572632762012\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0\tMRR:0\tP@1:0\tR1:0\tR2:0\tR5:0\n",
      "Batch[500] - loss: 0.146665  batch_size:32\n",
      "Batch[1000] - loss: 0.150953  batch_size:32\n",
      "Batch[1500] - loss: 0.183932  batch_size:32\n",
      "Batch[2000] - loss: 0.520116  batch_size:32\n",
      "Batch[2500] - loss: 0.200488  batch_size:32\n",
      "Batch[3000] - loss: 0.259220  batch_size:32\n",
      "Batch[3500] - loss: 0.370353  batch_size:32\n",
      "Batch[4000] - loss: 0.096686  batch_size:32\n",
      "Batch[4500] - loss: 0.181320  batch_size:32\n",
      "Average loss:0.245946 \n",
      "5561it [03:35, 25.78it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6120732147874718\tMRR:0.6120732147874718\tP@1:0.4637257656645125\tR1:0.4637257656645125\tR2:0.5889294745715089\tR5:0.8122506322000562\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0.6059656716484634\tMRR:0.6059656716484634\tP@1:0.4555774093846586\tR1:0.4555774093846586\tR2:0.582354593987075\tR5:0.8118572632762012\n",
      "save model!!!\n",
      "\n",
      "\n",
      "Epoch  3 / 100\n",
      "Batch[0] - loss: 0.198696  batch_size:32\n",
      "Batch[500] - loss: 0.075796  batch_size:32\n",
      "Batch[1000] - loss: 0.252392  batch_size:32\n",
      "Batch[1500] - loss: 0.187746  batch_size:32\n",
      "Batch[2000] - loss: 0.321089  batch_size:32\n",
      "Batch[2500] - loss: 0.359725  batch_size:32\n",
      "Batch[3000] - loss: 0.073656  batch_size:32\n",
      "Batch[3500] - loss: 0.127277  batch_size:32\n",
      "Batch[4000] - loss: 0.268391  batch_size:32\n",
      "Batch[4500] - loss: 0.128318  batch_size:32\n",
      "Average loss:0.222923 \n",
      "5561it [03:35, 25.82it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.61912259106135\tMRR:0.61912259106135\tP@1:0.4722112953076707\tR1:0.4722112953076707\tR2:0.5981455465018264\tR5:0.8187131216633886\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0.6120732147874718\tMRR:0.6120732147874718\tP@1:0.4637257656645125\tR1:0.4637257656645125\tR2:0.5889294745715089\tR5:0.8122506322000562\n",
      "save model!!!\n",
      "\n",
      "\n",
      "Epoch  4 / 100\n",
      "Batch[0] - loss: 0.266676  batch_size:32\n",
      "Batch[500] - loss: 0.133867  batch_size:32\n",
      "Batch[1000] - loss: 0.186772  batch_size:32\n",
      "Batch[1500] - loss: 0.058758  batch_size:32\n",
      "Batch[2000] - loss: 0.289814  batch_size:32\n",
      "Batch[2500] - loss: 0.178756  batch_size:32\n",
      "Batch[3000] - loss: 0.230494  batch_size:32\n",
      "Batch[3500] - loss: 0.432504  batch_size:32\n",
      "Batch[4000] - loss: 0.078999  batch_size:32\n",
      "Batch[4500] - loss: 0.132448  batch_size:32\n",
      "Average loss:0.192598 \n",
      "5561it [03:34, 25.91it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6050924550770133\tMRR:0.6050924550770133\tP@1:0.4527114357965721\tR1:0.4527114357965721\tR2:0.5833661140769879\tR5:0.8122506322000562\n",
      "\n",
      "Epoch  5 / 100\n",
      "Batch[0] - loss: 0.245639  batch_size:32\n",
      "Batch[500] - loss: 0.303529  batch_size:32\n",
      "Batch[1000] - loss: 0.133087  batch_size:32\n",
      "Batch[1500] - loss: 0.100708  batch_size:32\n",
      "Batch[2000] - loss: 0.022528  batch_size:32\n",
      "Batch[2500] - loss: 0.247651  batch_size:32\n",
      "Batch[3000] - loss: 0.141791  batch_size:32\n",
      "Batch[3500] - loss: 0.216417  batch_size:32\n",
      "Batch[4000] - loss: 0.141610  batch_size:32\n",
      "Batch[4500] - loss: 0.247764  batch_size:32\n",
      "Average loss:0.160393 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.5918593148601684\tMRR:0.5918593148601684\tP@1:0.43692048328182076\tR1:0.43692048328182076\tR2:0.5685304860915987\tR5:0.7985389154256813\n",
      "\n",
      "Epoch  6 / 100\n",
      "Batch[0] - loss: 0.073130  batch_size:32\n",
      "Batch[500] - loss: 0.097879  batch_size:32\n",
      "Batch[1000] - loss: 0.105922  batch_size:32\n",
      "Batch[1500] - loss: 0.034744  batch_size:32\n",
      "Batch[2000] - loss: 0.046444  batch_size:32\n",
      "Batch[2500] - loss: 0.052621  batch_size:32\n",
      "Batch[3000] - loss: 0.055334  batch_size:32\n",
      "Batch[3500] - loss: 0.199102  batch_size:32\n",
      "Batch[4000] - loss: 0.146232  batch_size:32\n",
      "Batch[4500] - loss: 0.096161  batch_size:32\n",
      "Average loss:0.128183 \n",
      "5561it [03:34, 25.91it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.5904287810469421\tMRR:0.5904287810469421\tP@1:0.4361899409946614\tR1:0.4361899409946614\tR2:0.5660016858668165\tR5:0.7944928350660297\n",
      "\n",
      "Epoch  7 / 100\n",
      "Batch[0] - loss: 0.084846  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  0.00025\n",
      "INFO:impchat:lr to:0.00025\n",
      "Batch[500] - loss: 0.220482  batch_size:32\n",
      "Batch[1000] - loss: 0.220498  batch_size:32\n",
      "Batch[1500] - loss: 0.182695  batch_size:32\n",
      "Batch[2000] - loss: 0.113482  batch_size:32\n",
      "Batch[2500] - loss: 0.123155  batch_size:32\n",
      "Batch[3000] - loss: 0.094967  batch_size:32\n",
      "Batch[3500] - loss: 0.303800  batch_size:32\n",
      "Batch[4000] - loss: 0.157676  batch_size:32\n",
      "Batch[4500] - loss: 0.072916  batch_size:32\n",
      "Average loss:0.173254 \n",
      "5561it [03:34, 25.88it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6101095590432593\tMRR:0.6101095590432593\tP@1:0.458274796291093\tR1:0.458274796291093\tR2:0.5882551278449003\tR5:0.8183197527395336\n",
      "\n",
      "Epoch  8 / 100\n",
      "Batch[0] - loss: 0.067431  batch_size:32\n",
      "Batch[500] - loss: 0.069481  batch_size:32\n",
      "Batch[1000] - loss: 0.106071  batch_size:32\n",
      "Batch[1500] - loss: 0.037159  batch_size:32\n",
      "Batch[2000] - loss: 0.088532  batch_size:32\n",
      "Batch[2500] - loss: 0.049837  batch_size:32\n",
      "Batch[3000] - loss: 0.261072  batch_size:32\n",
      "Batch[3500] - loss: 0.106885  batch_size:32\n",
      "Batch[4000] - loss: 0.041056  batch_size:32\n",
      "Batch[4500] - loss: 0.085846  batch_size:32\n",
      "Average loss:0.143558 \n",
      "5561it [03:34, 25.95it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.605081193665075\tMRR:0.605081193665075\tP@1:0.4534981736442821\tR1:0.4534981736442821\tR2:0.58196122506322\tR5:0.8104523742624332\n",
      "\n",
      "Epoch  9 / 100\n",
      "Batch[0] - loss: 0.135077  batch_size:32\n",
      "Batch[500] - loss: 0.113508  batch_size:32\n",
      "Batch[1000] - loss: 0.179801  batch_size:32\n",
      "Batch[1500] - loss: 0.065862  batch_size:32\n",
      "Batch[2000] - loss: 0.101131  batch_size:32\n",
      "Batch[2500] - loss: 0.147818  batch_size:32\n",
      "Batch[3000] - loss: 0.113060  batch_size:32\n",
      "Batch[3500] - loss: 0.125860  batch_size:32\n",
      "Batch[4000] - loss: 0.308402  batch_size:32\n",
      "Batch[4500] - loss: 0.017287  batch_size:32\n",
      "Average loss:0.113623 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.5961420632690754\tMRR:0.5961420632690754\tP@1:0.4419218881708345\tR1:0.4419218881708345\tR2:0.5698791795448159\tR5:0.8065748805844338\n",
      "\n",
      "Epoch  10 / 100\n",
      "Batch[0] - loss: 0.152531  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  0.000125\n",
      "INFO:impchat:lr to:0.000125\n",
      "Batch[500] - loss: 0.114768  batch_size:32\n",
      "Batch[1000] - loss: 0.059391  batch_size:32\n",
      "Batch[1500] - loss: 0.105218  batch_size:32\n",
      "Batch[2000] - loss: 0.200098  batch_size:32\n",
      "Batch[2500] - loss: 0.136457  batch_size:32\n",
      "Batch[3000] - loss: 0.199133  batch_size:32\n",
      "Batch[3500] - loss: 0.209200  batch_size:32\n",
      "Batch[4000] - loss: 0.041708  batch_size:32\n",
      "Batch[4500] - loss: 0.038707  batch_size:32\n",
      "Average loss:0.169690 \n",
      "5561it [03:34, 25.94it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6160085542131158\tMRR:0.6160085542131158\tP@1:0.46456869907277326\tR1:0.46456869907277326\tR2:0.5983703287440292\tR5:0.821410508569823\n",
      "\n",
      "Epoch  11 / 100\n",
      "Batch[0] - loss: 0.108817  batch_size:32\n",
      "Batch[500] - loss: 0.156318  batch_size:32\n",
      "Batch[1000] - loss: 0.058045  batch_size:32\n",
      "Batch[1500] - loss: 0.088620  batch_size:32\n",
      "Batch[2000] - loss: 0.137769  batch_size:32\n",
      "Batch[2500] - loss: 0.342974  batch_size:32\n",
      "Batch[3000] - loss: 0.046336  batch_size:32\n",
      "Batch[3500] - loss: 0.047143  batch_size:32\n",
      "Batch[4000] - loss: 0.019693  batch_size:32\n",
      "Batch[4500] - loss: 0.075315  batch_size:32\n",
      "Average loss:0.144907 \n",
      "5561it [03:34, 25.87it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6066843058287404\tMRR:0.6066843058287404\tP@1:0.4541725203708907\tR1:0.4541725203708907\tR2:0.5867940432705816\tR5:0.8133745434110705\n",
      "\n",
      "Epoch  12 / 100\n",
      "Batch[0] - loss: 0.134887  batch_size:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[500] - loss: 0.016066  batch_size:32\n",
      "Batch[1000] - loss: 0.089128  batch_size:32\n",
      "Batch[1500] - loss: 0.179554  batch_size:32\n",
      "Batch[2000] - loss: 0.174571  batch_size:32\n",
      "Batch[2500] - loss: 0.049616  batch_size:32\n",
      "Batch[3000] - loss: 0.080711  batch_size:32\n",
      "Batch[3500] - loss: 0.357738  batch_size:32\n",
      "Batch[4000] - loss: 0.205915  batch_size:32\n",
      "Batch[4500] - loss: 0.098011  batch_size:32\n",
      "Average loss:0.120259 \n",
      "5561it [03:35, 25.85it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.5977250386902071\tMRR:0.5977250386902071\tP@1:0.4443382972745153\tR1:0.4443382972745153\tR2:0.5732509131778589\tR5:0.8051137960101152\n",
      "\n",
      "Epoch  13 / 100\n",
      "Batch[0] - loss: 0.025361  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  6.25e-05\n",
      "INFO:impchat:lr to:6.25e-05\n",
      "Batch[500] - loss: 0.077563  batch_size:32\n",
      "Batch[1000] - loss: 0.156005  batch_size:32\n",
      "Batch[1500] - loss: 0.064967  batch_size:32\n",
      "Batch[2000] - loss: 0.048561  batch_size:32\n",
      "Batch[2500] - loss: 0.116703  batch_size:32\n",
      "Batch[3000] - loss: 0.031981  batch_size:32\n",
      "Batch[3500] - loss: 0.048986  batch_size:32\n",
      "Batch[4000] - loss: 0.264327  batch_size:32\n",
      "Batch[4500] - loss: 0.320298  batch_size:32\n",
      "Average loss:0.170879 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6137759402721586\tMRR:0.6137759402721586\tP@1:0.46322000561955606\tR1:0.46322000561955606\tR2:0.5921326215228997\tR5:0.8179825793762293\n",
      "\n",
      "Epoch  14 / 100\n",
      "Batch[0] - loss: 0.031341  batch_size:32\n",
      "Batch[500] - loss: 0.177833  batch_size:32\n",
      "Batch[1000] - loss: 0.174984  batch_size:32\n",
      "Batch[1500] - loss: 0.224406  batch_size:32\n",
      "Batch[2000] - loss: 0.261232  batch_size:32\n",
      "Batch[2500] - loss: 0.216681  batch_size:32\n",
      "Batch[3000] - loss: 0.167264  batch_size:32\n",
      "Batch[3500] - loss: 0.150231  batch_size:32\n",
      "Batch[4000] - loss: 0.114914  batch_size:32\n",
      "Batch[4500] - loss: 0.088636  batch_size:32\n",
      "Average loss:0.151469 \n",
      "5561it [03:34, 25.96it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6112005780114892\tMRR:0.6112005780114892\tP@1:0.4593987075021073\tR1:0.4593987075021073\tR2:0.5894352346164653\tR5:0.8175330148918235\n",
      "\n",
      "Epoch  15 / 100\n",
      "Batch[0] - loss: 0.080686  batch_size:32\n",
      "Batch[500] - loss: 0.044077  batch_size:32\n",
      "Batch[1000] - loss: 0.079717  batch_size:32\n",
      "Batch[1500] - loss: 0.142996  batch_size:32\n",
      "Batch[2000] - loss: 0.163316  batch_size:32\n",
      "Batch[2500] - loss: 0.069588  batch_size:32\n",
      "Batch[3000] - loss: 0.038952  batch_size:32\n",
      "Batch[3500] - loss: 0.125842  batch_size:32\n",
      "Batch[4000] - loss: 0.146927  batch_size:32\n",
      "Batch[4500] - loss: 0.030417  batch_size:32\n",
      "Average loss:0.135035 \n",
      "5561it [03:34, 25.90it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6080397784289435\tMRR:0.6080397784289435\tP@1:0.4555212138241079\tR1:0.4555212138241079\tR2:0.5878617589210452\tR5:0.812082045518404\n",
      "\n",
      "Epoch  16 / 100\n",
      "Batch[0] - loss: 0.114142  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  3.125e-05\n",
      "INFO:impchat:lr to:3.125e-05\n",
      "Batch[500] - loss: 0.095664  batch_size:32\n",
      "Batch[1500] - loss: 0.055435  batch_size:32\n",
      "Batch[2000] - loss: 0.241405  batch_size:32\n",
      "Batch[2500] - loss: 0.169490  batch_size:32\n",
      "Batch[3000] - loss: 0.195751  batch_size:32\n",
      "Batch[3500] - loss: 0.275200  batch_size:32\n",
      "Batch[4000] - loss: 0.185767  batch_size:32\n",
      "Batch[4500] - loss: 0.163672  batch_size:32\n",
      "Average loss:0.173541 \n",
      "5561it [03:35, 25.86it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195138415017702\tMRR:0.6195138415017702\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010115200899129\tR5:0.8221410508569823\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0.61912259106135\tMRR:0.61912259106135\tP@1:0.4722112953076707\tR1:0.4722112953076707\tR2:0.5981455465018264\tR5:0.8187131216633886\n",
      "save model!!!\n",
      "\n",
      "\n",
      "Epoch  17 / 100\n",
      "Batch[0] - loss: 0.037308  batch_size:32\n",
      "Batch[500] - loss: 0.085457  batch_size:32\n",
      "Batch[1000] - loss: 0.086600  batch_size:32\n",
      "Batch[1500] - loss: 0.091183  batch_size:32\n",
      "Batch[2000] - loss: 0.109357  batch_size:32\n",
      "Batch[2500] - loss: 0.082734  batch_size:32\n",
      "Batch[3000] - loss: 0.038120  batch_size:32\n",
      "Batch[3500] - loss: 0.201288  batch_size:32\n",
      "Batch[4000] - loss: 0.130819  batch_size:32\n",
      "Batch[4500] - loss: 0.150057  batch_size:32\n",
      "Average loss:0.158608 \n",
      "5561it [03:34, 25.93it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6154415365471945\tMRR:0.6154415365471945\tP@1:0.46395054790671536\tR1:0.46395054790671536\tR2:0.5964596796853049\tR5:0.8195560550716493\n",
      "\n",
      "Epoch  18 / 100\n",
      "Batch[0] - loss: 0.168527  batch_size:32\n",
      "Batch[500] - loss: 0.405161  batch_size:32\n",
      "Batch[1000] - loss: 0.082032  batch_size:32\n",
      "Batch[1500] - loss: 0.137253  batch_size:32\n",
      "Batch[2000] - loss: 0.132416  batch_size:32\n",
      "Batch[2500] - loss: 0.122381  batch_size:32\n",
      "Batch[3000] - loss: 0.119224  batch_size:32\n",
      "Batch[3500] - loss: 0.059274  batch_size:32\n",
      "Batch[4000] - loss: 0.160985  batch_size:32\n",
      "Batch[4500] - loss: 0.026361  batch_size:32\n",
      "Average loss:0.147938 \n",
      "5445it [03:29, 25.78it/s]INFO:impchat:Evaluation Result: \n",
      " MAP:0.6124015797196578\tMRR:0.6124015797196578\tP@1:0.46080359651587527\tR1:0.46080359651587527\tR2:0.5925259904467547\tR5:0.8184883394211857\n",
      "\n",
      "Epoch  19 / 100\n",
      "Batch[0] - loss: 0.131067  batch_size:32\n",
      "Batch[500] - loss: 0.143219  batch_size:32\n",
      "Batch[1000] - loss: 0.121516  batch_size:32\n",
      "Batch[1500] - loss: 0.089473  batch_size:32\n",
      "Batch[2000] - loss: 0.086038  batch_size:32\n",
      "Batch[2500] - loss: 0.030013  batch_size:32\n",
      "Batch[3000] - loss: 0.232975  batch_size:32\n",
      "Batch[3500] - loss: 0.084992  batch_size:32\n",
      "Batch[4000] - loss: 0.127611  batch_size:32\n",
      "Batch[4500] - loss: 0.047363  batch_size:32\n",
      "Average loss:0.138527 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.610509640214624\tMRR:0.610509640214624\tP@1:0.4579938184883394\tR1:0.4579938184883394\tR2:0.5906715369485811\tR5:0.8159033436358528\n",
      "\n",
      "Epoch  20 / 100\n",
      "Batch[0] - loss: 0.104563  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.5625e-05\n",
      "INFO:impchat:lr to:1.5625e-05\n",
      "Batch[500] - loss: 0.233686  batch_size:32\n",
      "Batch[1000] - loss: 0.153306  batch_size:32\n",
      "Batch[1500] - loss: 0.135711  batch_size:32\n",
      "Batch[2000] - loss: 0.132560  batch_size:32\n",
      "Batch[2500] - loss: 0.095488  batch_size:32\n",
      "Batch[3000] - loss: 0.123655  batch_size:32\n",
      "Batch[3500] - loss: 0.077896  batch_size:32\n",
      "Batch[4000] - loss: 0.198991  batch_size:32\n",
      "Batch[4500] - loss: 0.081355  batch_size:32\n",
      "Average loss:0.158856 \n",
      "5561it [03:34, 25.93it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6170828260123115\tMRR:0.6170828260123115\tP@1:0.46670413037370045\tR1:0.46670413037370045\tR2:0.5985389154256814\tR5:0.8199494239955043\n",
      "\n",
      "Epoch  21 / 100\n",
      "Batch[0] - loss: 0.083230  batch_size:32\n",
      "Batch[500] - loss: 0.191142  batch_size:32\n",
      "Batch[1000] - loss: 0.172104  batch_size:32\n",
      "Batch[1500] - loss: 0.224381  batch_size:32\n",
      "Batch[2000] - loss: 0.081299  batch_size:32\n",
      "Batch[2500] - loss: 0.041228  batch_size:32\n",
      "Batch[3000] - loss: 0.048688  batch_size:32\n",
      "Batch[3500] - loss: 0.039760  batch_size:32\n",
      "Batch[4000] - loss: 0.159871  batch_size:32\n",
      "Batch[4500] - loss: 0.066639  batch_size:32\n",
      "Average loss:0.153328 \n",
      "5561it [03:34, 25.88it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6148205087036336\tMRR:0.6148205087036336\tP@1:0.46288283225625176\tR1:0.46288283225625176\tR2:0.5964034841247542\tR5:0.8192750772688958\n",
      "\n",
      "Epoch  22 / 100\n",
      "Batch[0] - loss: 0.222507  batch_size:32\n",
      "Batch[500] - loss: 0.079489  batch_size:32\n",
      "Batch[1000] - loss: 0.040757  batch_size:32\n",
      "Batch[1500] - loss: 0.070367  batch_size:32\n",
      "Batch[2000] - loss: 0.160861  batch_size:32\n",
      "Batch[2500] - loss: 0.068374  batch_size:32\n",
      "Batch[3000] - loss: 0.099211  batch_size:32\n",
      "Batch[3500] - loss: 0.307258  batch_size:32\n",
      "Batch[4000] - loss: 0.279163  batch_size:32\n",
      "Batch[4500] - loss: 0.035189  batch_size:32\n",
      "Average loss:0.147779 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6131831886074756\tMRR:0.6131831886074756\tP@1:0.46147794324248387\tR1:0.46147794324248387\tR2:0.5929193593706097\tR5:0.8184883394211857\n",
      "\n",
      "Epoch  23 / 100\n",
      "Batch[0] - loss: 0.057583  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  7.8125e-06\n",
      "INFO:impchat:lr to:7.8125e-06\n",
      "Batch[500] - loss: 0.263709  batch_size:32\n",
      "Batch[1000] - loss: 0.183696  batch_size:32\n",
      "Batch[1500] - loss: 0.202954  batch_size:32\n",
      "Batch[2000] - loss: 0.235541  batch_size:32\n",
      "Batch[2500] - loss: 0.076484  batch_size:32\n",
      "Batch[3000] - loss: 0.024318  batch_size:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[3500] - loss: 0.189790  batch_size:32\n",
      "Batch[4000] - loss: 0.040832  batch_size:32\n",
      "Batch[4500] - loss: 0.345300  batch_size:32\n",
      "Average loss:0.159173 \n",
      "5561it [03:36, 25.74it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6181364927726377\tMRR:0.6181364927726377\tP@1:0.4681090193874684\tR1:0.4681090193874684\tR2:0.5992694577128407\tR5:0.8215228996909244\n",
      "\n",
      "Epoch  24 / 100\n",
      "Batch[0] - loss: 0.065054  batch_size:32\n",
      "Batch[500] - loss: 0.076377  batch_size:32\n",
      "Batch[1000] - loss: 0.067456  batch_size:32\n",
      "Batch[1500] - loss: 0.365805  batch_size:32\n",
      "Batch[2000] - loss: 0.139449  batch_size:32\n",
      "Batch[2500] - loss: 0.031808  batch_size:32\n",
      "Batch[3000] - loss: 0.099090  batch_size:32\n",
      "Batch[3500] - loss: 0.041278  batch_size:32\n",
      "Batch[4000] - loss: 0.082170  batch_size:32\n",
      "Batch[4500] - loss: 0.221230  batch_size:32\n",
      "Average loss:0.155646 \n",
      "5561it [03:35, 25.82it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.617022482684197\tMRR:0.617022482684197\tP@1:0.4664793481314976\tR1:0.4664793481314976\tR2:0.5979207642596235\tR5:0.8206237707221129\n",
      "\n",
      "Epoch  25 / 100\n",
      "Batch[0] - loss: 0.112399  batch_size:32\n",
      "Batch[500] - loss: 0.048870  batch_size:32\n",
      "Batch[1000] - loss: 0.205458  batch_size:32\n",
      "Batch[1500] - loss: 0.060291  batch_size:32\n",
      "Batch[2000] - loss: 0.231410  batch_size:32\n",
      "Batch[2500] - loss: 0.192392  batch_size:32\n",
      "Batch[3000] - loss: 0.220521  batch_size:32\n",
      "Batch[3500] - loss: 0.289930  batch_size:32\n",
      "Batch[4000] - loss: 0.190361  batch_size:32\n",
      "Batch[4500] - loss: 0.179742  batch_size:32\n",
      "Average loss:0.152705 \n",
      "5561it [03:34, 25.91it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6158310922008696\tMRR:0.6158310922008696\tP@1:0.4648496768755268\tR1:0.4648496768755268\tR2:0.5963472885642034\tR5:0.8184883394211857\n",
      "\n",
      "Epoch  26 / 100\n",
      "Batch[0] - loss: 0.028687  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  3.90625e-06\n",
      "INFO:impchat:lr to:3.90625e-06\n",
      "Batch[500] - loss: 0.142071  batch_size:32\n",
      "Batch[1000] - loss: 0.120516  batch_size:32\n",
      "Batch[1500] - loss: 0.075908  batch_size:32\n",
      "Batch[2000] - loss: 0.220565  batch_size:32\n",
      "Batch[2500] - loss: 0.315704  batch_size:32\n",
      "Batch[3000] - loss: 0.305080  batch_size:32\n",
      "Batch[3500] - loss: 0.157424  batch_size:32\n",
      "Batch[4000] - loss: 0.173662  batch_size:32\n",
      "Batch[4500] - loss: 0.239045  batch_size:32\n",
      "Average loss:0.159656 \n",
      "5561it [03:35, 25.82it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6185298839963171\tMRR:0.6185298839963171\tP@1:0.46833380162967125\tR1:0.46833380162967125\tR2:0.6006181511660579\tR5:0.822197246417533\n",
      "\n",
      "Epoch  27 / 100\n",
      "Batch[0] - loss: 0.102126  batch_size:32\n",
      "Batch[500] - loss: 0.030753  batch_size:32\n",
      "Batch[1000] - loss: 0.133314  batch_size:32\n",
      "Batch[1500] - loss: 0.111415  batch_size:32\n",
      "Batch[2000] - loss: 0.198985  batch_size:32\n",
      "Batch[2500] - loss: 0.080745  batch_size:32\n",
      "Batch[3000] - loss: 0.059433  batch_size:32\n",
      "Batch[3500] - loss: 0.373112  batch_size:32\n",
      "Batch[4000] - loss: 0.084669  batch_size:32\n",
      "Batch[4500] - loss: 0.319732  batch_size:32\n",
      "Average loss:0.157613 \n",
      "5561it [03:34, 25.88it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6173268530040201\tMRR:0.6173268530040201\tP@1:0.4668165214948019\tR1:0.4668165214948019\tR2:0.5983141331834785\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  28 / 100\n",
      "Batch[0] - loss: 0.175992  batch_size:32\n",
      "Batch[500] - loss: 0.378923  batch_size:32\n",
      "Batch[1000] - loss: 0.047979  batch_size:32\n",
      "Batch[1500] - loss: 0.086964  batch_size:32\n",
      "Batch[2000] - loss: 0.175856  batch_size:32\n",
      "Batch[2500] - loss: 0.060718  batch_size:32\n",
      "Batch[3000] - loss: 0.062216  batch_size:32\n",
      "Batch[3500] - loss: 0.196675  batch_size:32\n",
      "Batch[4000] - loss: 0.140295  batch_size:32\n",
      "Batch[4500] - loss: 0.179293  batch_size:32\n",
      "Average loss:0.155880 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6171297448454063\tMRR:0.6171297448454063\tP@1:0.4668165214948019\tR1:0.4668165214948019\tR2:0.5978645686990728\tR5:0.8209609440854172\n",
      "\n",
      "Epoch  29 / 100\n",
      "Batch[0] - loss: 0.138146  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.953125e-06\n",
      "INFO:impchat:lr to:1.953125e-06\n",
      "Batch[500] - loss: 0.119920  batch_size:32\n",
      "Batch[1000] - loss: 0.180150  batch_size:32\n",
      "Batch[1500] - loss: 0.266492  batch_size:32\n",
      "Batch[2000] - loss: 0.104661  batch_size:32\n",
      "Batch[2500] - loss: 0.287416  batch_size:32\n",
      "Batch[3000] - loss: 0.149934  batch_size:32\n",
      "Batch[3500] - loss: 0.162846  batch_size:32\n",
      "Batch[4000] - loss: 0.271457  batch_size:32\n",
      "Batch[4500] - loss: 0.085345  batch_size:32\n",
      "Average loss:0.159775 \n",
      "5561it [03:34, 25.92it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6191229701583842\tMRR:0.6191229701583842\tP@1:0.4692329305984827\tR1:0.4692329305984827\tR2:0.6015172801348694\tR5:0.821410508569823\n",
      "\n",
      "Epoch  30 / 100\n",
      "Batch[0] - loss: 0.197957  batch_size:32\n",
      "Batch[500] - loss: 0.136181  batch_size:32\n",
      "Batch[1000] - loss: 0.276913  batch_size:32\n",
      "Batch[1500] - loss: 0.117575  batch_size:32\n",
      "Batch[2000] - loss: 0.058187  batch_size:32\n",
      "Batch[2500] - loss: 0.080062  batch_size:32\n",
      "Batch[3000] - loss: 0.358506  batch_size:32\n",
      "Batch[3500] - loss: 0.132486  batch_size:32\n",
      "Batch[4000] - loss: 0.206745  batch_size:32\n",
      "Batch[4500] - loss: 0.300279  batch_size:32\n",
      "Average loss:0.158597 \n",
      "5561it [03:35, 25.78it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6188117314922701\tMRR:0.6188117314922701\tP@1:0.4688957572351784\tR1:0.4688957572351784\tR2:0.6006181511660579\tR5:0.8219724641753301\n",
      "\n",
      "Epoch  31 / 100\n",
      "Batch[0] - loss: 0.190979  batch_size:32\n",
      "Batch[500] - loss: 0.099292  batch_size:32\n",
      "Batch[1000] - loss: 0.218098  batch_size:32\n",
      "Batch[1500] - loss: 0.288415  batch_size:32\n",
      "Batch[2000] - loss: 0.289028  batch_size:32\n",
      "Batch[2500] - loss: 0.211823  batch_size:32\n",
      "Batch[3000] - loss: 0.177562  batch_size:32\n",
      "Batch[3500] - loss: 0.274192  batch_size:32\n",
      "Batch[4000] - loss: 0.078179  batch_size:32\n",
      "Batch[4500] - loss: 0.152443  batch_size:32\n",
      "Average loss:0.157574 \n",
      "5561it [03:34, 25.91it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6184094872378203\tMRR:0.6184094872378203\tP@1:0.46827760606912056\tR1:0.46827760606912056\tR2:0.5997752177577972\tR5:0.8223096375386344\n",
      "\n",
      "Epoch  32 / 100\n",
      "Batch[0] - loss: 0.104387  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  9.765625e-07\n",
      "INFO:impchat:lr to:9.765625e-07\n",
      "Batch[500] - loss: 0.226358  batch_size:32\n",
      "Batch[1000] - loss: 0.276348  batch_size:32\n",
      "Batch[1500] - loss: 0.225736  batch_size:32\n",
      "Batch[2000] - loss: 0.226137  batch_size:32\n",
      "Batch[2500] - loss: 0.253318  batch_size:32\n",
      "Batch[3000] - loss: 0.149577  batch_size:32\n",
      "Batch[3500] - loss: 0.062989  batch_size:32\n",
      "Batch[4000] - loss: 0.320246  batch_size:32\n",
      "Batch[4500] - loss: 0.075771  batch_size:32\n",
      "Average loss:0.159889 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6193260546702625\tMRR:0.6193260546702625\tP@1:0.46962629952233775\tR1:0.46962629952233775\tR2:0.6011801067715651\tR5:0.8215790952514751\n",
      "\n",
      "Epoch  33 / 100\n",
      "Batch[0] - loss: 0.276588  batch_size:32\n",
      "Batch[500] - loss: 0.197631  batch_size:32\n",
      "Batch[1000] - loss: 0.300120  batch_size:32\n",
      "Batch[1500] - loss: 0.085687  batch_size:32\n",
      "Batch[2000] - loss: 0.156208  batch_size:32\n",
      "Batch[2500] - loss: 0.033591  batch_size:32\n",
      "Batch[3000] - loss: 0.037168  batch_size:32\n",
      "Batch[3500] - loss: 0.061702  batch_size:32\n",
      "Batch[4000] - loss: 0.067422  batch_size:32\n",
      "Batch[4500] - loss: 0.323267  batch_size:32\n",
      "Average loss:0.159150 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192924488330607\tMRR:0.6192924488330607\tP@1:0.469570103961787\tR1:0.469570103961787\tR2:0.6014610845743187\tR5:0.8214667041303737\n",
      "\n",
      "Epoch  34 / 100\n",
      "Batch[0] - loss: 0.190019  batch_size:32\n",
      "Batch[500] - loss: 0.201922  batch_size:32\n",
      "Batch[1000] - loss: 0.238393  batch_size:32\n",
      "Batch[1500] - loss: 0.163362  batch_size:32\n",
      "Batch[2000] - loss: 0.169946  batch_size:32\n",
      "Batch[2500] - loss: 0.059441  batch_size:32\n",
      "Batch[3000] - loss: 0.336860  batch_size:32\n",
      "Batch[3500] - loss: 0.232602  batch_size:32\n",
      "Batch[4000] - loss: 0.183095  batch_size:32\n",
      "Batch[4500] - loss: 0.199630  batch_size:32\n",
      "Average loss:0.158683 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6191118202455761\tMRR:0.6191118202455761\tP@1:0.46928912615903345\tR1:0.46928912615903345\tR2:0.6012924978926665\tR5:0.8216352908120258\n",
      "\n",
      "Epoch  35 / 100\n",
      "Batch[0] - loss: 0.092219  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  4.8828125e-07\n",
      "INFO:impchat:lr to:4.8828125e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[500] - loss: 0.159692  batch_size:32\n",
      "Batch[1000] - loss: 0.250321  batch_size:32\n",
      "Batch[1500] - loss: 0.062768  batch_size:32\n",
      "Batch[2000] - loss: 0.114981  batch_size:32\n",
      "Batch[2500] - loss: 0.038599  batch_size:32\n",
      "Batch[3000] - loss: 0.117195  batch_size:32\n",
      "Batch[3500] - loss: 0.179530  batch_size:32\n",
      "Batch[4000] - loss: 0.133104  batch_size:32\n",
      "Batch[4500] - loss: 0.134746  batch_size:32\n",
      "Average loss:0.160208 \n",
      "5561it [03:34, 25.92it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192007073504788\tMRR:0.6192007073504788\tP@1:0.46962629952233775\tR1:0.46962629952233775\tR2:0.6006743467266086\tR5:0.8216914863725766\n",
      "\n",
      "Epoch  36 / 100\n",
      "Batch[0] - loss: 0.185672  batch_size:32\n",
      "Batch[500] - loss: 0.226904  batch_size:32\n",
      "Batch[1000] - loss: 0.190707  batch_size:32\n",
      "Batch[1500] - loss: 0.268002  batch_size:32\n",
      "Batch[2000] - loss: 0.265236  batch_size:32\n",
      "Batch[2500] - loss: 0.045513  batch_size:32\n",
      "Batch[3000] - loss: 0.206002  batch_size:32\n",
      "Batch[3500] - loss: 0.120509  batch_size:32\n",
      "Batch[4000] - loss: 0.051600  batch_size:32\n",
      "Batch[4500] - loss: 0.160324  batch_size:32\n",
      "Average loss:0.159702 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192698145100605\tMRR:0.6192698145100605\tP@1:0.469570103961787\tR1:0.469570103961787\tR2:0.6010677156504636\tR5:0.8214667041303737\n",
      "\n",
      "Epoch  37 / 100\n",
      "Batch[0] - loss: 0.202842  batch_size:32\n",
      "Batch[500] - loss: 0.132249  batch_size:32\n",
      "Batch[1000] - loss: 0.180777  batch_size:32\n",
      "Batch[1500] - loss: 0.061381  batch_size:32\n",
      "Batch[2000] - loss: 0.118571  batch_size:32\n",
      "Batch[2500] - loss: 0.292519  batch_size:32\n",
      "Batch[3000] - loss: 0.187336  batch_size:32\n",
      "Batch[3500] - loss: 0.182757  batch_size:32\n",
      "Batch[4000] - loss: 0.141071  batch_size:32\n",
      "Batch[4500] - loss: 0.142160  batch_size:32\n",
      "Average loss:0.159437 \n",
      "5561it [03:34, 25.88it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619274876570476\tMRR:0.619274876570476\tP@1:0.4694577128406856\tR1:0.4694577128406856\tR2:0.6016296712559708\tR5:0.8216352908120258\n",
      "\n",
      "Epoch  38 / 100\n",
      "Batch[0] - loss: 0.191534  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  2.44140625e-07\n",
      "INFO:impchat:lr to:2.44140625e-07\n",
      "Batch[500] - loss: 0.361897  batch_size:32\n",
      "Batch[1000] - loss: 0.149038  batch_size:32\n",
      "Batch[1500] - loss: 0.213912  batch_size:32\n",
      "Batch[2000] - loss: 0.381219  batch_size:32\n",
      "Batch[2500] - loss: 0.035293  batch_size:32\n",
      "Batch[3000] - loss: 0.135441  batch_size:32\n",
      "Batch[3500] - loss: 0.068757  batch_size:32\n",
      "Batch[4000] - loss: 0.145381  batch_size:32\n",
      "Batch[4500] - loss: 0.248089  batch_size:32\n",
      "Average loss:0.160025 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6191078285767914\tMRR:0.6191078285767914\tP@1:0.4694577128406856\tR1:0.4694577128406856\tR2:0.600393368923855\tR5:0.8220848552964316\n",
      "\n",
      "Epoch  39 / 100\n",
      "Batch[0] - loss: 0.036401  batch_size:32\n",
      "Batch[500] - loss: 0.211632  batch_size:32\n",
      "Batch[1000] - loss: 0.146862  batch_size:32\n",
      "Batch[1500] - loss: 0.072325  batch_size:32\n",
      "Batch[2000] - loss: 0.142033  batch_size:32\n",
      "Batch[2500] - loss: 0.089025  batch_size:32\n",
      "Batch[3000] - loss: 0.042465  batch_size:32\n",
      "Batch[3500] - loss: 0.327125  batch_size:32\n",
      "Batch[4000] - loss: 0.081884  batch_size:32\n",
      "Batch[4500] - loss: 0.150467  batch_size:32\n",
      "Average loss:0.159837 \n",
      "5561it [03:35, 25.79it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619231079712967\tMRR:0.619231079712967\tP@1:0.46968249508288845\tR1:0.46968249508288845\tR2:0.6006181511660579\tR5:0.8216352908120258\n",
      "\n",
      "Epoch  40 / 100\n",
      "Batch[0] - loss: 0.242782  batch_size:32\n",
      "Batch[500] - loss: 0.161584  batch_size:32\n",
      "Batch[1000] - loss: 0.106623  batch_size:32\n",
      "Batch[1500] - loss: 0.052519  batch_size:32\n",
      "Batch[2000] - loss: 0.277929  batch_size:32\n",
      "Batch[2500] - loss: 0.212036  batch_size:32\n",
      "Batch[3000] - loss: 0.027863  batch_size:32\n",
      "Batch[3500] - loss: 0.197457  batch_size:32\n",
      "Batch[4000] - loss: 0.149566  batch_size:32\n",
      "Batch[4500] - loss: 0.351498  batch_size:32\n",
      "Average loss:0.159723 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192601809853948\tMRR:0.6192601809853948\tP@1:0.46962629952233775\tR1:0.46962629952233775\tR2:0.6008991289688115\tR5:0.8214667041303737\n",
      "\n",
      "Epoch  41 / 100\n",
      "Batch[0] - loss: 0.085999  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.220703125e-07\n",
      "INFO:impchat:lr to:1.220703125e-07\n",
      "Batch[500] - loss: 0.289169  batch_size:32\n",
      "Batch[1000] - loss: 0.034272  batch_size:32\n",
      "Batch[1500] - loss: 0.182694  batch_size:32\n",
      "Batch[2000] - loss: 0.074733  batch_size:32\n",
      "Batch[2500] - loss: 0.160201  batch_size:32\n",
      "Batch[3000] - loss: 0.181135  batch_size:32\n",
      "Batch[3500] - loss: 0.092475  batch_size:32\n",
      "Batch[4000] - loss: 0.175729  batch_size:32\n",
      "Batch[4500] - loss: 0.188754  batch_size:32\n",
      "Average loss:0.160044 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192678744252327\tMRR:0.6192678744252327\tP@1:0.46968249508288845\tR1:0.46968249508288845\tR2:0.6005057600449565\tR5:0.8219162686147794\n",
      "\n",
      "Epoch  42 / 100\n",
      "Batch[0] - loss: 0.154966  batch_size:32\n",
      "Batch[500] - loss: 0.161243  batch_size:32\n",
      "Batch[1000] - loss: 0.035072  batch_size:32\n",
      "Batch[1500] - loss: 0.117863  batch_size:32\n",
      "Batch[2000] - loss: 0.107613  batch_size:32\n",
      "Batch[2500] - loss: 0.070562  batch_size:32\n",
      "Batch[3000] - loss: 0.053404  batch_size:32\n",
      "Batch[3500] - loss: 0.055777  batch_size:32\n",
      "Batch[4000] - loss: 0.298908  batch_size:32\n",
      "Batch[4500] - loss: 0.149439  batch_size:32\n",
      "Average loss:0.160076 \n",
      "5561it [03:35, 25.85it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6190384984189531\tMRR:0.6190384984189531\tP@1:0.46934532171958415\tR1:0.46934532171958415\tR2:0.6002809778027536\tR5:0.8219724641753301\n",
      "\n",
      "Epoch  43 / 100\n",
      "Batch[0] - loss: 0.330207  batch_size:32\n",
      "Batch[500] - loss: 0.186036  batch_size:32\n",
      "Batch[1000] - loss: 0.216216  batch_size:32\n",
      "Batch[1500] - loss: 0.135964  batch_size:32\n",
      "Batch[2000] - loss: 0.033411  batch_size:32\n",
      "Batch[2500] - loss: 0.074959  batch_size:32\n",
      "Batch[3000] - loss: 0.172003  batch_size:32\n",
      "Batch[3500] - loss: 0.087586  batch_size:32\n",
      "Batch[4000] - loss: 0.103047  batch_size:32\n",
      "Batch[4500] - loss: 0.232261  batch_size:32\n",
      "Average loss:0.159940 \n",
      "5561it [03:35, 25.76it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6191522944290683\tMRR:0.6191522944290683\tP@1:0.4695139084012363\tR1:0.4695139084012363\tR2:0.6005619556055072\tR5:0.8216914863725766\n",
      "\n",
      "Epoch  44 / 100\n",
      "Batch[0] - loss: 0.133604  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  6.103515625e-08\n",
      "INFO:impchat:lr to:6.103515625e-08\n",
      "Batch[500] - loss: 0.133266  batch_size:32\n",
      "Batch[1000] - loss: 0.151615  batch_size:32\n",
      "Batch[1500] - loss: 0.057170  batch_size:32\n",
      "Batch[2000] - loss: 0.303981  batch_size:32\n",
      "Batch[2500] - loss: 0.096589  batch_size:32\n",
      "Batch[3000] - loss: 0.053895  batch_size:32\n",
      "Batch[3500] - loss: 0.119651  batch_size:32\n",
      "Batch[4000] - loss: 0.135462  batch_size:32\n",
      "Batch[4500] - loss: 0.260942  batch_size:32\n",
      "Average loss:0.160311 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192814996186834\tMRR:0.6192814996186834\tP@1:0.4695139084012363\tR1:0.4695139084012363\tR2:0.6008991289688115\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  45 / 100\n",
      "Batch[0] - loss: 0.317542  batch_size:32\n",
      "Batch[500] - loss: 0.180106  batch_size:32\n",
      "Batch[1000] - loss: 0.204018  batch_size:32\n",
      "Batch[1500] - loss: 0.192445  batch_size:32\n",
      "Batch[2000] - loss: 0.153244  batch_size:32\n",
      "Batch[2500] - loss: 0.096574  batch_size:32\n",
      "Batch[3000] - loss: 0.077069  batch_size:32\n",
      "Batch[3500] - loss: 0.152061  batch_size:32\n",
      "Batch[4000] - loss: 0.163595  batch_size:32\n",
      "Batch[4500] - loss: 0.090622  batch_size:32\n",
      "Average loss:0.160098 \n",
      "5561it [03:35, 25.79it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619235093681578\tMRR:0.619235093681578\tP@1:0.46962629952233775\tR1:0.46962629952233775\tR2:0.6004495644844058\tR5:0.8219162686147794\n",
      "\n",
      "Epoch  46 / 100\n",
      "Batch[0] - loss: 0.075305  batch_size:32\n",
      "Batch[500] - loss: 0.089221  batch_size:32\n",
      "Batch[1000] - loss: 0.085576  batch_size:32\n",
      "Batch[1500] - loss: 0.217212  batch_size:32\n",
      "Batch[2000] - loss: 0.055829  batch_size:32\n",
      "Batch[2500] - loss: 0.276136  batch_size:32\n",
      "Batch[3000] - loss: 0.141043  batch_size:32\n",
      "Batch[3500] - loss: 0.146081  batch_size:32\n",
      "Batch[4000] - loss: 0.080589  batch_size:32\n",
      "Batch[4500] - loss: 0.049158  batch_size:32\n",
      "Average loss:0.159902 \n",
      "5561it [03:34, 25.91it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6191844953772566\tMRR:0.6191844953772566\tP@1:0.46962629952233775\tR1:0.46962629952233775\tR2:0.6001685866816522\tR5:0.8219724641753301\n",
      "\n",
      "Epoch  47 / 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[0] - loss: 0.059796  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  3.0517578125e-08\n",
      "INFO:impchat:lr to:3.0517578125e-08\n",
      "Batch[500] - loss: 0.341661  batch_size:32\n",
      "Batch[1000] - loss: 0.181455  batch_size:32\n",
      "Batch[1500] - loss: 0.265983  batch_size:32\n",
      "Batch[2000] - loss: 0.195293  batch_size:32\n",
      "Batch[2500] - loss: 0.251670  batch_size:32\n",
      "Batch[3000] - loss: 0.163623  batch_size:32\n",
      "Batch[3500] - loss: 0.276538  batch_size:32\n",
      "Batch[4000] - loss: 0.098593  batch_size:32\n",
      "Batch[4500] - loss: 0.388905  batch_size:32\n",
      "Average loss:0.160242 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194444667442807\tMRR:0.6194444667442807\tP@1:0.4697948862039899\tR1:0.4697948862039899\tR2:0.6010115200899129\tR5:0.8222534419780837\n",
      "\n",
      "Epoch  48 / 100\n",
      "Batch[0] - loss: 0.125453  batch_size:32\n",
      "Batch[500] - loss: 0.051796  batch_size:32\n",
      "Batch[1000] - loss: 0.191328  batch_size:32\n",
      "Batch[1500] - loss: 0.174676  batch_size:32\n",
      "Batch[2000] - loss: 0.157818  batch_size:32\n",
      "Batch[2500] - loss: 0.132386  batch_size:32\n",
      "Batch[3000] - loss: 0.029310  batch_size:32\n",
      "Batch[3500] - loss: 0.041546  batch_size:32\n",
      "Batch[4000] - loss: 0.237250  batch_size:32\n",
      "Batch[4500] - loss: 0.187282  batch_size:32\n",
      "Average loss:0.160286 \n",
      "5561it [03:35, 25.76it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192852459893868\tMRR:0.6192852459893868\tP@1:0.4695139084012363\tR1:0.4695139084012363\tR2:0.6009553245293622\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  49 / 100\n",
      "Batch[0] - loss: 0.050290  batch_size:32\n",
      "Batch[500] - loss: 0.132325  batch_size:32\n",
      "Batch[1000] - loss: 0.073821  batch_size:32\n",
      "Batch[1500] - loss: 0.129031  batch_size:32\n",
      "Batch[2000] - loss: 0.164378  batch_size:32\n",
      "Batch[2500] - loss: 0.065469  batch_size:32\n",
      "Batch[3000] - loss: 0.065581  batch_size:32\n",
      "Batch[3500] - loss: 0.304569  batch_size:32\n",
      "Batch[4000] - loss: 0.239009  batch_size:32\n",
      "Batch[4500] - loss: 0.233829  batch_size:32\n",
      "Average loss:0.160161 \n",
      "5561it [03:35, 25.86it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6192150238385241\tMRR:0.6192150238385241\tP@1:0.4694577128406856\tR1:0.4694577128406856\tR2:0.6007305422871593\tR5:0.8220286597358809\n",
      "\n",
      "Epoch  50 / 100\n",
      "Batch[0] - loss: 0.254816  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.52587890625e-08\n",
      "INFO:impchat:lr to:1.52587890625e-08\n",
      "Batch[500] - loss: 0.126188  batch_size:32\n",
      "Batch[1000] - loss: 0.203632  batch_size:32\n",
      "Batch[1500] - loss: 0.361585  batch_size:32\n",
      "Batch[2000] - loss: 0.107006  batch_size:32\n",
      "Batch[2500] - loss: 0.087312  batch_size:32\n",
      "Batch[3000] - loss: 0.412737  batch_size:32\n",
      "Batch[3500] - loss: 0.285472  batch_size:32\n",
      "Batch[4000] - loss: 0.115278  batch_size:32\n",
      "Batch[4500] - loss: 0.038655  batch_size:32\n",
      "Average loss:0.160270 \n",
      "5561it [03:35, 25.82it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194686620550736\tMRR:0.6194686620550736\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  51 / 100\n",
      "Batch[0] - loss: 0.166563  batch_size:32\n",
      "Batch[500] - loss: 0.060089  batch_size:32\n",
      "Batch[1000] - loss: 0.175194  batch_size:32\n",
      "Batch[1500] - loss: 0.135635  batch_size:32\n",
      "Batch[2000] - loss: 0.130117  batch_size:32\n",
      "Batch[2500] - loss: 0.338225  batch_size:32\n",
      "Batch[3000] - loss: 0.401235  batch_size:32\n",
      "Batch[3500] - loss: 0.087518  batch_size:32\n",
      "Batch[4000] - loss: 0.053807  batch_size:32\n",
      "Batch[4500] - loss: 0.032539  batch_size:32\n",
      "Average loss:0.160094 \n",
      "5561it [03:35, 25.85it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194793659713689\tMRR:0.6194793659713689\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "\n",
      "Epoch  52 / 100\n",
      "Batch[0] - loss: 0.090996  batch_size:32\n",
      "Batch[500] - loss: 0.078219  batch_size:32\n",
      "Batch[1000] - loss: 0.029996  batch_size:32\n",
      "Batch[1500] - loss: 0.276443  batch_size:32\n",
      "Batch[2000] - loss: 0.193161  batch_size:32\n",
      "Batch[2500] - loss: 0.034278  batch_size:32\n",
      "Batch[3000] - loss: 0.216197  batch_size:32\n",
      "Batch[3500] - loss: 0.080297  batch_size:32\n",
      "Batch[4000] - loss: 0.073639  batch_size:32\n",
      "Batch[4500] - loss: 0.130000  batch_size:32\n",
      "Average loss:0.160036 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194039702609632\tMRR:0.6194039702609632\tP@1:0.46973869064343915\tR1:0.46973869064343915\tR2:0.6008991289688115\tR5:0.8222534419780837\n",
      "\n",
      "Epoch  53 / 100\n",
      "Batch[0] - loss: 0.111900  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  7.62939453125e-09\n",
      "INFO:impchat:lr to:7.62939453125e-09\n",
      "Batch[500] - loss: 0.053640  batch_size:32\n",
      "Batch[1000] - loss: 0.084660  batch_size:32\n",
      "Batch[1500] - loss: 0.056764  batch_size:32\n",
      "Batch[2000] - loss: 0.149888  batch_size:32\n",
      "Batch[2500] - loss: 0.227277  batch_size:32\n",
      "Batch[3000] - loss: 0.244223  batch_size:32\n",
      "Batch[3500] - loss: 0.085595  batch_size:32\n",
      "Batch[4000] - loss: 0.154868  batch_size:32\n",
      "Batch[4500] - loss: 0.392445  batch_size:32\n",
      "Average loss:0.160233 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195185244651495\tMRR:0.6195185244651495\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0.6195138415017702\tMRR:0.6195138415017702\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010115200899129\tR5:0.8221410508569823\n",
      "save model!!!\n",
      "\n",
      "\n",
      "Epoch  54 / 100\n",
      "Batch[0] - loss: 0.290616  batch_size:32\n",
      "Batch[500] - loss: 0.145696  batch_size:32\n",
      "Batch[1000] - loss: 0.044693  batch_size:32\n",
      "Batch[1500] - loss: 0.189883  batch_size:32\n",
      "Batch[2000] - loss: 0.317465  batch_size:32\n",
      "Batch[2500] - loss: 0.269933  batch_size:32\n",
      "Batch[3000] - loss: 0.083213  batch_size:32\n",
      "Batch[3500] - loss: 0.133756  batch_size:32\n",
      "Batch[4000] - loss: 0.389913  batch_size:32\n",
      "Batch[4500] - loss: 0.232988  batch_size:32\n",
      "Average loss:0.160176 \n",
      "5561it [03:35, 25.85it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194646034868114\tMRR:0.6194646034868114\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  55 / 100\n",
      "Batch[0] - loss: 0.197910  batch_size:32\n",
      "Batch[500] - loss: 0.075562  batch_size:32\n",
      "Batch[1000] - loss: 0.160025  batch_size:32\n",
      "Batch[1500] - loss: 0.345807  batch_size:32\n",
      "Batch[2000] - loss: 0.118502  batch_size:32\n",
      "Batch[2500] - loss: 0.056913  batch_size:32\n",
      "Batch[3000] - loss: 0.071025  batch_size:32\n",
      "Batch[3500] - loss: 0.212698  batch_size:32\n",
      "Batch[4000] - loss: 0.145519  batch_size:32\n",
      "Batch[4500] - loss: 0.145642  batch_size:32\n",
      "Average loss:0.160208 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194499302015566\tMRR:0.6194499302015566\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6010115200899129\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  56 / 100\n",
      "Batch[0] - loss: 0.180787  batch_size:32\n",
      "Batch[500] - loss: 0.157941  batch_size:32\n",
      "Batch[1000] - loss: 0.142224  batch_size:32\n",
      "Batch[1500] - loss: 0.058871  batch_size:32\n",
      "Batch[2000] - loss: 0.112952  batch_size:32\n",
      "Batch[2500] - loss: 0.043679  batch_size:32\n",
      "Batch[3000] - loss: 0.209092  batch_size:32\n",
      "Batch[3500] - loss: 0.144735  batch_size:32\n",
      "Batch[4000] - loss: 0.183826  batch_size:32\n",
      "Batch[4500] - loss: 0.113077  batch_size:32\n",
      "Average loss:0.160340 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194868587127755\tMRR:0.6194868587127755\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010115200899129\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  57 / 100\n",
      "Batch[0] - loss: 0.222038  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  3.814697265625e-09\n",
      "INFO:impchat:lr to:3.814697265625e-09\n",
      "Batch[500] - loss: 0.105152  batch_size:32\n",
      "Batch[1000] - loss: 0.095098  batch_size:32\n",
      "Batch[1500] - loss: 0.324535  batch_size:32\n",
      "Batch[2000] - loss: 0.156521  batch_size:32\n",
      "Batch[2500] - loss: 0.248673  batch_size:32\n",
      "Batch[3000] - loss: 0.376214  batch_size:32\n",
      "Batch[3500] - loss: 0.248598  batch_size:32\n",
      "Batch[4000] - loss: 0.265133  batch_size:32\n",
      "Batch[4500] - loss: 0.058386  batch_size:32\n",
      "Average loss:0.160282 \n",
      "5561it [03:34, 25.88it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195185244651497\tMRR:0.6195185244651497\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  58 / 100\n",
      "Batch[0] - loss: 0.242878  batch_size:32\n",
      "Batch[500] - loss: 0.219232  batch_size:32\n",
      "Batch[1000] - loss: 0.162595  batch_size:32\n",
      "Batch[1500] - loss: 0.138385  batch_size:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[2000] - loss: 0.256326  batch_size:32\n",
      "Batch[2500] - loss: 0.132237  batch_size:32\n",
      "Batch[3000] - loss: 0.086845  batch_size:32\n",
      "Batch[3500] - loss: 0.068352  batch_size:32\n",
      "Batch[4000] - loss: 0.153530  batch_size:32\n",
      "Batch[4500] - loss: 0.270923  batch_size:32\n",
      "Average loss:0.160264 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194557727558678\tMRR:0.6194557727558678\tP@1:0.4697948862039899\tR1:0.4697948862039899\tR2:0.6011801067715651\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  59 / 100\n",
      "Batch[0] - loss: 0.200314  batch_size:32\n",
      "Batch[500] - loss: 0.042584  batch_size:32\n",
      "Batch[1000] - loss: 0.113090  batch_size:32\n",
      "Batch[1500] - loss: 0.257228  batch_size:32\n",
      "Batch[2000] - loss: 0.085484  batch_size:32\n",
      "Batch[2500] - loss: 0.136028  batch_size:32\n",
      "Batch[3000] - loss: 0.138122  batch_size:32\n",
      "Batch[3500] - loss: 0.247780  batch_size:32\n",
      "Batch[4000] - loss: 0.130227  batch_size:32\n",
      "Batch[4500] - loss: 0.081436  batch_size:32\n",
      "Average loss:0.160234 \n",
      "5561it [03:34, 25.92it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619472631424033\tMRR:0.619472631424033\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  60 / 100\n",
      "Batch[0] - loss: 0.063020  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.9073486328125e-09\n",
      "INFO:impchat:lr to:1.9073486328125e-09\n",
      "Batch[500] - loss: 0.110179  batch_size:32\n",
      "Batch[1000] - loss: 0.108044  batch_size:32\n",
      "Batch[1500] - loss: 0.126975  batch_size:32\n",
      "Batch[2000] - loss: 0.175575  batch_size:32\n",
      "Batch[2500] - loss: 0.194230  batch_size:32\n",
      "Batch[3000] - loss: 0.045066  batch_size:32\n",
      "Batch[3500] - loss: 0.250071  batch_size:32\n",
      "Batch[4000] - loss: 0.050525  batch_size:32\n",
      "Batch[4500] - loss: 0.230816  batch_size:32\n",
      "Average loss:0.160239 \n",
      "5561it [03:35, 25.75it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195003278074473\tMRR:0.6195003278074473\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  61 / 100\n",
      "Batch[0] - loss: 0.175927  batch_size:32\n",
      "Batch[500] - loss: 0.118760  batch_size:32\n",
      "Batch[1000] - loss: 0.177726  batch_size:32\n",
      "Batch[1500] - loss: 0.245614  batch_size:32\n",
      "Batch[2000] - loss: 0.197325  batch_size:32\n",
      "Batch[2500] - loss: 0.118377  batch_size:32\n",
      "Batch[3000] - loss: 0.103022  batch_size:32\n",
      "Batch[3500] - loss: 0.055306  batch_size:32\n",
      "Batch[4000] - loss: 0.078138  batch_size:32\n",
      "Batch[4500] - loss: 0.269762  batch_size:32\n",
      "Average loss:0.160197 \n",
      "5561it [03:34, 25.87it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195185244651497\tMRR:0.6195185244651497\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  62 / 100\n",
      "Batch[0] - loss: 0.157191  batch_size:32\n",
      "Batch[500] - loss: 0.048234  batch_size:32\n",
      "Batch[1000] - loss: 0.153815  batch_size:32\n",
      "Batch[1500] - loss: 0.147311  batch_size:32\n",
      "Batch[2000] - loss: 0.358080  batch_size:32\n",
      "Batch[2500] - loss: 0.081514  batch_size:32\n",
      "Batch[3000] - loss: 0.259822  batch_size:32\n",
      "Batch[3500] - loss: 0.134109  batch_size:32\n",
      "Batch[4000] - loss: 0.179421  batch_size:32\n",
      "Batch[4500] - loss: 0.153269  batch_size:32\n",
      "Average loss:0.160260 \n",
      "5561it [03:35, 25.83it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195171864756127\tMRR:0.6195171864756127\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  63 / 100\n",
      "Batch[0] - loss: 0.256586  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  9.5367431640625e-10\n",
      "INFO:impchat:lr to:9.5367431640625e-10\n",
      "Batch[500] - loss: 0.159930  batch_size:32\n",
      "Batch[1000] - loss: 0.055011  batch_size:32\n",
      "Batch[1500] - loss: 0.072516  batch_size:32\n",
      "Batch[2000] - loss: 0.283626  batch_size:32\n",
      "Batch[2500] - loss: 0.052583  batch_size:32\n",
      "Batch[3000] - loss: 0.109581  batch_size:32\n",
      "Batch[3500] - loss: 0.165170  batch_size:32\n",
      "Batch[4000] - loss: 0.163433  batch_size:32\n",
      "Batch[4500] - loss: 0.042418  batch_size:32\n",
      "Average loss:0.160133 \n",
      "5561it [03:35, 25.84it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195213342431771\tMRR:0.6195213342431771\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  64 / 100\n",
      "Batch[0] - loss: 0.385162  batch_size:32\n",
      "Batch[500] - loss: 0.398317  batch_size:32\n",
      "Batch[1000] - loss: 0.035174  batch_size:32\n",
      "Batch[1500] - loss: 0.081313  batch_size:32\n",
      "Batch[2000] - loss: 0.131499  batch_size:32\n",
      "Batch[2500] - loss: 0.064168  batch_size:32\n",
      "Batch[3000] - loss: 0.147263  batch_size:32\n",
      "Batch[3500] - loss: 0.124232  batch_size:32\n",
      "Batch[4000] - loss: 0.319439  batch_size:32\n",
      "Batch[4500] - loss: 0.179663  batch_size:32\n",
      "Average loss:0.160255 \n",
      "5561it [03:34, 25.89it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194951096482535\tMRR:0.6194951096482535\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "\n",
      "Epoch  65 / 100\n",
      "Batch[0] - loss: 0.076879  batch_size:32\n",
      "Batch[500] - loss: 0.320124  batch_size:32\n",
      "Batch[1000] - loss: 0.216086  batch_size:32\n",
      "Batch[1500] - loss: 0.197273  batch_size:32\n",
      "Batch[2000] - loss: 0.264143  batch_size:32\n",
      "Batch[2500] - loss: 0.269572  batch_size:32\n",
      "Batch[3000] - loss: 0.136675  batch_size:32\n",
      "Batch[3500] - loss: 0.097047  batch_size:32\n",
      "Batch[4000] - loss: 0.097523  batch_size:32\n",
      "Batch[4500] - loss: 0.218344  batch_size:32\n",
      "Average loss:0.160338 \n",
      "5561it [03:33, 26.02it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194750398051995\tMRR:0.6194750398051995\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011801067715651\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  66 / 100\n",
      "Batch[0] - loss: 0.160656  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  4.76837158203125e-10\n",
      "INFO:impchat:lr to:4.76837158203125e-10\n",
      "Batch[500] - loss: 0.234298  batch_size:32\n",
      "Batch[1000] - loss: 0.253472  batch_size:32\n",
      "Batch[1500] - loss: 0.159050  batch_size:32\n",
      "Batch[2000] - loss: 0.207988  batch_size:32\n",
      "Batch[2500] - loss: 0.237594  batch_size:32\n",
      "Batch[3000] - loss: 0.046234  batch_size:32\n",
      "Batch[3500] - loss: 0.237400  batch_size:32\n",
      "Batch[4000] - loss: 0.026034  batch_size:32\n",
      "Batch[4500] - loss: 0.207362  batch_size:32\n",
      "Average loss:0.160317 \n",
      "5561it [03:30, 26.47it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195185244651495\tMRR:0.6195185244651495\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "\n",
      "Epoch  67 / 100\n",
      "Batch[0] - loss: 0.086443  batch_size:32\n",
      "Batch[500] - loss: 0.214710  batch_size:32\n",
      "Batch[1000] - loss: 0.259809  batch_size:32\n",
      "Batch[1500] - loss: 0.139961  batch_size:32\n",
      "Batch[2000] - loss: 0.188980  batch_size:32\n",
      "Batch[2500] - loss: 0.338372  batch_size:32\n",
      "Batch[3000] - loss: 0.219588  batch_size:32\n",
      "Batch[3500] - loss: 0.229044  batch_size:32\n",
      "Batch[4000] - loss: 0.240258  batch_size:32\n",
      "Batch[4500] - loss: 0.141441  batch_size:32\n",
      "Average loss:0.160306 \n",
      "5561it [03:30, 26.39it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195372563186664\tMRR:0.6195372563186664\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011801067715651\tR5:0.822197246417533\n",
      "INFO:impchat:Best Result: \n",
      " MAP:0.6195185244651495\tMRR:0.6195185244651495\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "save model!!!\n",
      "\n",
      "\n",
      "Epoch  68 / 100\n",
      "Batch[0] - loss: 0.060566  batch_size:32\n",
      "Batch[500] - loss: 0.127202  batch_size:32\n",
      "Batch[1000] - loss: 0.175513  batch_size:32\n",
      "Batch[1500] - loss: 0.071243  batch_size:32\n",
      "Batch[2000] - loss: 0.224427  batch_size:32\n",
      "Batch[2500] - loss: 0.322996  batch_size:32\n",
      "Batch[3000] - loss: 0.192174  batch_size:32\n",
      "Batch[3500] - loss: 0.244047  batch_size:32\n",
      "Batch[4000] - loss: 0.156229  batch_size:32\n",
      "Batch[4500] - loss: 0.087436  batch_size:32\n",
      "Average loss:0.160409 \n",
      "5561it [03:30, 26.48it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619497919426281\tMRR:0.619497919426281\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  69 / 100\n",
      "Batch[0] - loss: 0.111963  batch_size:32\n",
      "Batch[500] - loss: 0.215142  batch_size:32\n",
      "Batch[1500] - loss: 0.293212  batch_size:32\n",
      "Batch[2000] - loss: 0.143718  batch_size:32\n",
      "Batch[2500] - loss: 0.167468  batch_size:32\n",
      "Batch[3000] - loss: 0.265462  batch_size:32\n",
      "Batch[3500] - loss: 0.177542  batch_size:32\n",
      "Batch[4000] - loss: 0.116729  batch_size:32\n",
      "Batch[4500] - loss: 0.043912  batch_size:32\n",
      "Average loss:0.160130 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5561it [03:30, 26.43it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194904266848742\tMRR:0.6194904266848742\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "\n",
      "Epoch  70 / 100\n",
      "Batch[0] - loss: 0.145893  batch_size:32\n",
      "Batch[500] - loss: 0.203194  batch_size:32\n",
      "Batch[1000] - loss: 0.047504  batch_size:32\n",
      "Batch[1500] - loss: 0.188148  batch_size:32\n",
      "Batch[2000] - loss: 0.162005  batch_size:32\n",
      "Batch[2500] - loss: 0.167973  batch_size:32\n",
      "Batch[3000] - loss: 0.062775  batch_size:32\n",
      "Batch[3500] - loss: 0.080282  batch_size:32\n",
      "Batch[4000] - loss: 0.094699  batch_size:32\n",
      "Batch[4500] - loss: 0.127050  batch_size:32\n",
      "Average loss:0.160111 \n",
      "5561it [03:30, 26.44it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195260172065563\tMRR:0.6195260172065563\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  71 / 100\n",
      "Batch[0] - loss: 0.294128  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  2.384185791015625e-10\n",
      "INFO:impchat:lr to:2.384185791015625e-10\n",
      "Batch[500] - loss: 0.467270  batch_size:32\n",
      "Batch[1000] - loss: 0.139008  batch_size:32\n",
      "Batch[1500] - loss: 0.196205  batch_size:32\n",
      "Batch[2000] - loss: 0.088492  batch_size:32\n",
      "Batch[2500] - loss: 0.235331  batch_size:32\n",
      "Batch[3000] - loss: 0.136212  batch_size:32\n",
      "Batch[3500] - loss: 0.330328  batch_size:32\n",
      "Batch[4000] - loss: 0.157831  batch_size:32\n",
      "Batch[4500] - loss: 0.252217  batch_size:32\n",
      "Average loss:0.160202 \n",
      "5561it [03:30, 26.37it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195072853530393\tMRR:0.6195072853530393\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011801067715651\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  72 / 100\n",
      "Batch[0] - loss: 0.122391  batch_size:32\n",
      "Batch[500] - loss: 0.344594  batch_size:32\n",
      "Batch[1000] - loss: 0.225818  batch_size:32\n",
      "Batch[1500] - loss: 0.186730  batch_size:32\n",
      "Batch[2000] - loss: 0.118539  batch_size:32\n",
      "Batch[2500] - loss: 0.103291  batch_size:32\n",
      "Batch[3000] - loss: 0.129171  batch_size:32\n",
      "Batch[3500] - loss: 0.097271  batch_size:32\n",
      "Batch[4000] - loss: 0.051952  batch_size:32\n",
      "Batch[4500] - loss: 0.199889  batch_size:32\n",
      "Average loss:0.160289 \n",
      "5561it [03:30, 26.47it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194885534995225\tMRR:0.6194885534995225\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  73 / 100\n",
      "Batch[0] - loss: 0.104975  batch_size:32\n",
      "Batch[500] - loss: 0.219580  batch_size:32\n",
      "Batch[1000] - loss: 0.058416  batch_size:32\n",
      "Batch[1500] - loss: 0.130269  batch_size:32\n",
      "Batch[2000] - loss: 0.080974  batch_size:32\n",
      "Batch[2500] - loss: 0.054206  batch_size:32\n",
      "Batch[3000] - loss: 0.047411  batch_size:32\n",
      "Batch[3500] - loss: 0.165021  batch_size:32\n",
      "Batch[4000] - loss: 0.067711  batch_size:32\n",
      "Batch[4500] - loss: 0.104966  batch_size:32\n",
      "Average loss:0.160226 \n",
      "5561it [03:30, 26.37it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194698216460056\tMRR:0.6194698216460056\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  74 / 100\n",
      "Batch[0] - loss: 0.230889  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.1920928955078125e-10\n",
      "INFO:impchat:lr to:1.1920928955078125e-10\n",
      "Batch[500] - loss: 0.166743  batch_size:32\n",
      "Batch[1000] - loss: 0.095794  batch_size:32\n",
      "Batch[1500] - loss: 0.233690  batch_size:32\n",
      "Batch[2000] - loss: 0.049085  batch_size:32\n",
      "Batch[2500] - loss: 0.127949  batch_size:32\n",
      "Batch[3000] - loss: 0.235547  batch_size:32\n",
      "Batch[3500] - loss: 0.077309  batch_size:32\n",
      "Batch[4000] - loss: 0.059160  batch_size:32\n",
      "Batch[4500] - loss: 0.103930  batch_size:32\n",
      "Average loss:0.160389 \n",
      "5561it [03:29, 26.49it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194763777947365\tMRR:0.6194763777947365\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  75 / 100\n",
      "Batch[0] - loss: 0.141158  batch_size:32\n",
      "Batch[500] - loss: 0.061713  batch_size:32\n",
      "Batch[1000] - loss: 0.164221  batch_size:32\n",
      "Batch[1500] - loss: 0.260098  batch_size:32\n",
      "Batch[2000] - loss: 0.068734  batch_size:32\n",
      "Batch[2500] - loss: 0.404277  batch_size:32\n",
      "Batch[3000] - loss: 0.188296  batch_size:32\n",
      "Batch[3500] - loss: 0.261598  batch_size:32\n",
      "Batch[4000] - loss: 0.285415  batch_size:32\n",
      "Batch[4500] - loss: 0.219003  batch_size:32\n",
      "Average loss:0.160394 \n",
      "5561it [03:30, 26.41it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194932364629018\tMRR:0.6194932364629018\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  76 / 100\n",
      "Batch[0] - loss: 0.199787  batch_size:32\n",
      "Batch[500] - loss: 0.390949  batch_size:32\n",
      "Batch[1000] - loss: 0.053109  batch_size:32\n",
      "Batch[1500] - loss: 0.105906  batch_size:32\n",
      "Batch[2000] - loss: 0.254820  batch_size:32\n",
      "Batch[2500] - loss: 0.183778  batch_size:32\n",
      "Batch[3000] - loss: 0.246271  batch_size:32\n",
      "Batch[3500] - loss: 0.533525  batch_size:32\n",
      "Batch[4000] - loss: 0.139990  batch_size:32\n",
      "Batch[4500] - loss: 0.051793  batch_size:32\n",
      "Average loss:0.160346 \n",
      "5561it [03:30, 26.47it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195138415017702\tMRR:0.6195138415017702\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011801067715651\tR5:0.822197246417533\n",
      "\n",
      "Epoch  77 / 100\n",
      "Batch[0] - loss: 0.136471  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  5.960464477539063e-11\n",
      "INFO:impchat:lr to:5.960464477539063e-11\n",
      "Batch[500] - loss: 0.091911  batch_size:32\n",
      "Batch[1000] - loss: 0.270461  batch_size:32\n",
      "Batch[1500] - loss: 0.240517  batch_size:32\n",
      "Batch[2000] - loss: 0.348687  batch_size:32\n",
      "Batch[2500] - loss: 0.084955  batch_size:32\n",
      "Batch[3000] - loss: 0.286965  batch_size:32\n",
      "Batch[3500] - loss: 0.089436  batch_size:32\n",
      "Batch[4000] - loss: 0.071001  batch_size:32\n",
      "Batch[4500] - loss: 0.089302  batch_size:32\n",
      "Average loss:0.160405 \n",
      "5561it [03:30, 26.40it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195213342431771\tMRR:0.6195213342431771\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  78 / 100\n",
      "Batch[0] - loss: 0.311481  batch_size:32\n",
      "Batch[500] - loss: 0.141730  batch_size:32\n",
      "Batch[1000] - loss: 0.094252  batch_size:32\n",
      "Batch[1500] - loss: 0.114161  batch_size:32\n",
      "Batch[2000] - loss: 0.145212  batch_size:32\n",
      "Batch[2500] - loss: 0.092016  batch_size:32\n",
      "Batch[3000] - loss: 0.036745  batch_size:32\n",
      "Batch[3500] - loss: 0.249790  batch_size:32\n",
      "Batch[4000] - loss: 0.227633  batch_size:32\n",
      "Batch[4500] - loss: 0.038535  batch_size:32\n",
      "Average loss:0.160229 \n",
      "5561it [03:30, 26.48it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194810607581157\tMRR:0.6194810607581157\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011801067715651\tR5:0.822197246417533\n",
      "\n",
      "Epoch  79 / 100\n",
      "Batch[0] - loss: 0.249771  batch_size:32\n",
      "Batch[500] - loss: 0.324510  batch_size:32\n",
      "Batch[1000] - loss: 0.041130  batch_size:32\n",
      "Batch[1500] - loss: 0.058645  batch_size:32\n",
      "Batch[2000] - loss: 0.073510  batch_size:32\n",
      "Batch[2500] - loss: 0.161403  batch_size:32\n",
      "Batch[3000] - loss: 0.119878  batch_size:32\n",
      "Batch[3500] - loss: 0.284871  batch_size:32\n",
      "Batch[4000] - loss: 0.071527  batch_size:32\n",
      "Batch[4500] - loss: 0.225475  batch_size:32\n",
      "Average loss:0.160275 \n",
      "5561it [03:30, 26.46it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194997926116326\tMRR:0.6194997926116326\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  80 / 100\n",
      "Batch[0] - loss: 0.059040  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  2.980232238769531e-11\n",
      "INFO:impchat:lr to:2.980232238769531e-11\n",
      "Batch[500] - loss: 0.103342  batch_size:32\n",
      "Batch[1000] - loss: 0.120591  batch_size:32\n",
      "Batch[1500] - loss: 0.058374  batch_size:32\n",
      "Batch[2000] - loss: 0.403580  batch_size:32\n",
      "Batch[2500] - loss: 0.137255  batch_size:32\n",
      "Batch[3000] - loss: 0.281647  batch_size:32\n",
      "Batch[3500] - loss: 0.120843  batch_size:32\n",
      "Batch[4000] - loss: 0.411725  batch_size:32\n",
      "Batch[4500] - loss: 0.155986  batch_size:32\n",
      "Average loss:0.160178 \n",
      "5561it [03:29, 26.48it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195325733552872\tMRR:0.6195325733552872\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  81 / 100\n",
      "Batch[0] - loss: 0.232835  batch_size:32\n",
      "Batch[500] - loss: 0.271286  batch_size:32\n",
      "Batch[1000] - loss: 0.068133  batch_size:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[1500] - loss: 0.032712  batch_size:32\n",
      "Batch[2000] - loss: 0.030648  batch_size:32\n",
      "Batch[2500] - loss: 0.090682  batch_size:32\n",
      "Batch[3000] - loss: 0.188991  batch_size:32\n",
      "Batch[3500] - loss: 0.281283  batch_size:32\n",
      "Batch[4000] - loss: 0.391401  batch_size:32\n",
      "Batch[4500] - loss: 0.206786  batch_size:32\n",
      "Average loss:0.160174 \n",
      "5561it [03:29, 26.49it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195138415017702\tMRR:0.6195138415017702\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011801067715651\tR5:0.822197246417533\n",
      "\n",
      "Epoch  82 / 100\n",
      "Batch[0] - loss: 0.049477  batch_size:32\n",
      "Batch[500] - loss: 0.108786  batch_size:32\n",
      "Batch[1000] - loss: 0.469521  batch_size:32\n",
      "Batch[1500] - loss: 0.092281  batch_size:32\n",
      "Batch[2000] - loss: 0.230960  batch_size:32\n",
      "Batch[2500] - loss: 0.204799  batch_size:32\n",
      "Batch[3000] - loss: 0.160296  batch_size:32\n",
      "Batch[3500] - loss: 0.040091  batch_size:32\n",
      "Batch[4000] - loss: 0.103904  batch_size:32\n",
      "Batch[4500] - loss: 0.121895  batch_size:32\n",
      "Average loss:0.160232 \n",
      "5561it [03:30, 26.48it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194885534995225\tMRR:0.6194885534995225\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  83 / 100\n",
      "Batch[0] - loss: 0.130454  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.4901161193847657e-11\n",
      "INFO:impchat:lr to:1.4901161193847657e-11\n",
      "Batch[500] - loss: 0.174292  batch_size:32\n",
      "Batch[1000] - loss: 0.202426  batch_size:32\n",
      "Batch[1500] - loss: 0.121670  batch_size:32\n",
      "Batch[2000] - loss: 0.071508  batch_size:32\n",
      "Batch[2500] - loss: 0.039560  batch_size:32\n",
      "Batch[3000] - loss: 0.251599  batch_size:32\n",
      "Batch[3500] - loss: 0.144874  batch_size:32\n",
      "Batch[4000] - loss: 0.172673  batch_size:32\n",
      "Batch[4500] - loss: 0.159388  batch_size:32\n",
      "Average loss:0.160346 \n",
      "5561it [03:30, 26.43it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194932364629018\tMRR:0.6194932364629018\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  84 / 100\n",
      "Batch[0] - loss: 0.115407  batch_size:32\n",
      "Batch[500] - loss: 0.088333  batch_size:32\n",
      "Batch[1000] - loss: 0.061919  batch_size:32\n",
      "Batch[1500] - loss: 0.276161  batch_size:32\n",
      "Batch[2000] - loss: 0.094702  batch_size:32\n",
      "Batch[2500] - loss: 0.300923  batch_size:32\n",
      "Batch[3000] - loss: 0.406724  batch_size:32\n",
      "Batch[3500] - loss: 0.289201  batch_size:32\n",
      "Batch[4000] - loss: 0.236405  batch_size:32\n",
      "Batch[4500] - loss: 0.070541  batch_size:32\n",
      "Average loss:0.160209 \n",
      "5561it [03:30, 26.45it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619497919426281\tMRR:0.619497919426281\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  85 / 100\n",
      "Batch[0] - loss: 0.341670  batch_size:32\n",
      "Batch[500] - loss: 0.425387  batch_size:32\n",
      "Batch[1000] - loss: 0.244704  batch_size:32\n",
      "Batch[1500] - loss: 0.110795  batch_size:32\n",
      "Batch[2000] - loss: 0.133926  batch_size:32\n",
      "Batch[2500] - loss: 0.108231  batch_size:32\n",
      "Batch[3000] - loss: 0.147936  batch_size:32\n",
      "Batch[3500] - loss: 0.140797  batch_size:32\n",
      "Batch[4000] - loss: 0.048642  batch_size:32\n",
      "Batch[4500] - loss: 0.113912  batch_size:32\n",
      "Average loss:0.160172 \n",
      "5561it [03:30, 26.44it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194745046093848\tMRR:0.6194745046093848\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  86 / 100\n",
      "Batch[0] - loss: 0.099372  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  7.450580596923828e-12\n",
      "INFO:impchat:lr to:7.450580596923828e-12\n",
      "Batch[500] - loss: 0.392423  batch_size:32\n",
      "Batch[1000] - loss: 0.037924  batch_size:32\n",
      "Batch[1500] - loss: 0.140096  batch_size:32\n",
      "Batch[2000] - loss: 0.276635  batch_size:32\n",
      "Batch[2500] - loss: 0.183737  batch_size:32\n",
      "Batch[3000] - loss: 0.040338  batch_size:32\n",
      "Batch[3500] - loss: 0.094772  batch_size:32\n",
      "Batch[4000] - loss: 0.160639  batch_size:32\n",
      "Batch[4500] - loss: 0.053762  batch_size:32\n",
      "Average loss:0.160282 \n",
      "5561it [03:30, 26.41it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.619497919426281\tMRR:0.619497919426281\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  87 / 100\n",
      "Batch[0] - loss: 0.203004  batch_size:32\n",
      "Batch[500] - loss: 0.062483  batch_size:32\n",
      "Batch[1000] - loss: 0.124946  batch_size:32\n",
      "Batch[1500] - loss: 0.147604  batch_size:32\n",
      "Batch[2000] - loss: 0.040898  batch_size:32\n",
      "Batch[2500] - loss: 0.205627  batch_size:32\n",
      "Batch[3000] - loss: 0.081037  batch_size:32\n",
      "Batch[3500] - loss: 0.032603  batch_size:32\n",
      "Batch[4000] - loss: 0.126310  batch_size:32\n",
      "Batch[4500] - loss: 0.287608  batch_size:32\n",
      "Average loss:0.160280 \n",
      "5561it [03:30, 26.46it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195307001699356\tMRR:0.6195307001699356\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  88 / 100\n",
      "Batch[0] - loss: 0.227428  batch_size:32\n",
      "Batch[500] - loss: 0.103861  batch_size:32\n",
      "Batch[1000] - loss: 0.172000  batch_size:32\n",
      "Batch[1500] - loss: 0.076733  batch_size:32\n",
      "Batch[2000] - loss: 0.243079  batch_size:32\n",
      "Batch[2500] - loss: 0.160358  batch_size:32\n",
      "Batch[3000] - loss: 0.403473  batch_size:32\n",
      "Batch[3500] - loss: 0.222197  batch_size:32\n",
      "Batch[4000] - loss: 0.145655  batch_size:32\n",
      "Batch[4500] - loss: 0.243666  batch_size:32\n",
      "Average loss:0.160283 \n",
      "5561it [03:30, 26.38it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195260172065563\tMRR:0.6195260172065563\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  89 / 100\n",
      "Batch[0] - loss: 0.043924  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  3.725290298461914e-12\n",
      "INFO:impchat:lr to:3.725290298461914e-12\n",
      "Batch[500] - loss: 0.201436  batch_size:32\n",
      "Batch[1000] - loss: 0.352255  batch_size:32\n",
      "Batch[1500] - loss: 0.154154  batch_size:32\n",
      "Batch[2000] - loss: 0.253455  batch_size:32\n",
      "Batch[2500] - loss: 0.248531  batch_size:32\n",
      "Batch[3000] - loss: 0.204358  batch_size:32\n",
      "Batch[3500] - loss: 0.061423  batch_size:32\n",
      "Batch[4000] - loss: 0.051238  batch_size:32\n",
      "Batch[4500] - loss: 0.096493  batch_size:32\n",
      "Average loss:0.160345 \n",
      "5561it [03:30, 26.44it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195026023896603\tMRR:0.6195026023896603\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  90 / 100\n",
      "Batch[0] - loss: 0.092604  batch_size:32\n",
      "Batch[500] - loss: 0.391707  batch_size:32\n",
      "Batch[1000] - loss: 0.147357  batch_size:32\n",
      "Batch[1500] - loss: 0.045925  batch_size:32\n",
      "Batch[2000] - loss: 0.190783  batch_size:32\n",
      "Batch[2500] - loss: 0.062184  batch_size:32\n",
      "Batch[3000] - loss: 0.111296  batch_size:32\n",
      "Batch[3500] - loss: 0.332873  batch_size:32\n",
      "Batch[4000] - loss: 0.196045  batch_size:32\n",
      "Batch[4500] - loss: 0.142071  batch_size:32\n",
      "Average loss:0.160217 \n",
      "5561it [03:30, 26.41it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194716948313572\tMRR:0.6194716948313572\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  91 / 100\n",
      "Batch[0] - loss: 0.110502  batch_size:32\n",
      "Batch[500] - loss: 0.169463  batch_size:32\n",
      "Batch[1000] - loss: 0.228717  batch_size:32\n",
      "Batch[1500] - loss: 0.045729  batch_size:32\n",
      "Batch[2000] - loss: 0.097241  batch_size:32\n",
      "Batch[2500] - loss: 0.208812  batch_size:32\n",
      "Batch[3000] - loss: 0.092284  batch_size:32\n",
      "Batch[3500] - loss: 0.145867  batch_size:32\n",
      "Batch[4000] - loss: 0.290532  batch_size:32\n",
      "Batch[4500] - loss: 0.092264  batch_size:32\n",
      "Average loss:0.160314 \n",
      "5561it [03:30, 26.46it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195278903919079\tMRR:0.6195278903919079\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  92 / 100\n",
      "Batch[0] - loss: 0.203109  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  1.862645149230957e-12\n",
      "INFO:impchat:lr to:1.862645149230957e-12\n",
      "Batch[500] - loss: 0.029483  batch_size:32\n",
      "Batch[1000] - loss: 0.121443  batch_size:32\n",
      "Batch[1500] - loss: 0.046716  batch_size:32\n",
      "Batch[2000] - loss: 0.238955  batch_size:32\n",
      "Batch[2500] - loss: 0.161564  batch_size:32\n",
      "Batch[3000] - loss: 0.077129  batch_size:32\n",
      "Batch[3500] - loss: 0.275726  batch_size:32\n",
      "Batch[4000] - loss: 0.129908  batch_size:32\n",
      "Batch[4500] - loss: 0.037235  batch_size:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.160392 \n",
      "5508it [03:28, 26.50it/s]Batch[500] - loss: 0.146017  batch_size:32\n",
      "Batch[1000] - loss: 0.095187  batch_size:32\n",
      "Batch[1500] - loss: 0.087297  batch_size:32\n",
      "Batch[2000] - loss: 0.171582  batch_size:32\n",
      "Batch[2500] - loss: 0.101329  batch_size:32\n",
      "Batch[3000] - loss: 0.172935  batch_size:32\n",
      "Batch[3500] - loss: 0.044227  batch_size:32\n",
      "Batch[4000] - loss: 0.065884  batch_size:32\n",
      "Batch[4500] - loss: 0.484394  batch_size:32\n",
      "Average loss:0.160245 \n",
      "5561it [03:30, 26.48it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194716948313572\tMRR:0.6194716948313572\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  94 / 100\n",
      "Batch[0] - loss: 0.127673  batch_size:32\n",
      "Batch[500] - loss: 0.257509  batch_size:32\n",
      "Batch[1000] - loss: 0.048921  batch_size:32\n",
      "Batch[1500] - loss: 0.223776  batch_size:32\n",
      "Batch[2000] - loss: 0.043266  batch_size:32\n",
      "Batch[2500] - loss: 0.157175  batch_size:32\n",
      "Batch[3000] - loss: 0.203167  batch_size:32\n",
      "Batch[3500] - loss: 0.157635  batch_size:32\n",
      "Batch[4000] - loss: 0.347418  batch_size:32\n",
      "Batch[4500] - loss: 0.148072  batch_size:32\n",
      "Average loss:0.160288 \n",
      "5561it [03:29, 26.54it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194904266848742\tMRR:0.6194904266848742\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6010677156504636\tR5:0.822197246417533\n",
      "\n",
      "Epoch  95 / 100\n",
      "Batch[0] - loss: 0.132379  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  9.313225746154785e-13\n",
      "INFO:impchat:lr to:9.313225746154785e-13\n",
      "Batch[500] - loss: 0.175449  batch_size:32\n",
      "Batch[1000] - loss: 0.161867  batch_size:32\n",
      "Batch[1500] - loss: 0.133511  batch_size:32\n",
      "Batch[2000] - loss: 0.044003  batch_size:32\n",
      "Batch[2500] - loss: 0.224850  batch_size:32\n",
      "Batch[3000] - loss: 0.169303  batch_size:32\n",
      "Batch[3500] - loss: 0.077385  batch_size:32\n",
      "Batch[4000] - loss: 0.150001  batch_size:32\n",
      "Batch[4500] - loss: 0.039557  batch_size:32\n",
      "Average loss:0.160390 \n",
      "5561it [03:29, 26.51it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195044755750119\tMRR:0.6195044755750119\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  96 / 100\n",
      "Batch[0] - loss: 0.112836  batch_size:32\n",
      "Batch[500] - loss: 0.113447  batch_size:32\n",
      "Batch[1000] - loss: 0.304165  batch_size:32\n",
      "Batch[1500] - loss: 0.276419  batch_size:32\n",
      "Batch[2000] - loss: 0.172894  batch_size:32\n",
      "Batch[2500] - loss: 0.088775  batch_size:32\n",
      "Batch[3000] - loss: 0.199902  batch_size:32\n",
      "Batch[3500] - loss: 0.043924  batch_size:32\n",
      "Batch[4000] - loss: 0.098586  batch_size:32\n",
      "Batch[4500] - loss: 0.214064  batch_size:32\n",
      "Average loss:0.160165 \n",
      "5561it [03:29, 26.49it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195325733552872\tMRR:0.6195325733552872\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  97 / 100\n",
      "Batch[0] - loss: 0.052699  batch_size:32\n",
      "Batch[500] - loss: 0.185722  batch_size:32\n",
      "Batch[1000] - loss: 0.247404  batch_size:32\n",
      "Batch[1500] - loss: 0.238783  batch_size:32\n",
      "Batch[2000] - loss: 0.317466  batch_size:32\n",
      "Batch[2500] - loss: 0.266875  batch_size:32\n",
      "Batch[3000] - loss: 0.039293  batch_size:32\n",
      "Batch[3500] - loss: 0.192268  batch_size:32\n",
      "Batch[4000] - loss: 0.179079  batch_size:32\n",
      "Batch[4500] - loss: 0.103988  batch_size:32\n",
      "Average loss:0.160271 \n",
      "5561it [03:29, 26.50it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195278903919079\tMRR:0.6195278903919079\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "\n",
      "Epoch  98 / 100\n",
      "Batch[0] - loss: 0.284078  batch_size:32\n",
      "INFO:impchat:Reload the best model...\n",
      "Decay learning rate to:  4.656612873077393e-13\n",
      "INFO:impchat:lr to:4.656612873077393e-13\n",
      "Batch[500] - loss: 0.147574  batch_size:32\n",
      "Batch[1000] - loss: 0.288621  batch_size:32\n",
      "Batch[1500] - loss: 0.051317  batch_size:32\n",
      "Batch[2000] - loss: 0.030798  batch_size:32\n",
      "Batch[2500] - loss: 0.087473  batch_size:32\n",
      "Batch[3000] - loss: 0.169911  batch_size:32\n",
      "Batch[3500] - loss: 0.056459  batch_size:32\n",
      "Batch[4000] - loss: 0.132488  batch_size:32\n",
      "Batch[4500] - loss: 0.238400  batch_size:32\n",
      "Average loss:0.160456 \n",
      "5561it [03:31, 26.30it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195419392820457\tMRR:0.6195419392820457\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011801067715651\tR5:0.822197246417533\n",
      "\n",
      "Epoch  99 / 100\n",
      "Batch[0] - loss: 0.128528  batch_size:32\n",
      "Batch[500] - loss: 0.209828  batch_size:32\n",
      "Batch[1000] - loss: 0.164156  batch_size:32\n",
      "Batch[1500] - loss: 0.317102  batch_size:32\n",
      "Batch[2000] - loss: 0.154432  batch_size:32\n",
      "Batch[2500] - loss: 0.063076  batch_size:32\n",
      "Batch[3000] - loss: 0.050941  batch_size:32\n",
      "Batch[3500] - loss: 0.121622  batch_size:32\n",
      "Batch[4000] - loss: 0.141928  batch_size:32\n",
      "Batch[4500] - loss: 0.032178  batch_size:32\n",
      "Average loss:0.160349 \n",
      "5561it [03:31, 26.27it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6194698216460056\tMRR:0.6194698216460056\tP@1:0.4698510817645406\tR1:0.4698510817645406\tR2:0.6011239112110144\tR5:0.8221410508569823\n",
      "\n",
      "Epoch  100 / 100\n",
      "Batch[0] - loss: 0.161461  batch_size:32\n",
      "Batch[500] - loss: 0.132624  batch_size:32\n",
      "Batch[1500] - loss: 0.045642  batch_size:32\n",
      "Batch[2000] - loss: 0.256016  batch_size:32\n",
      "Batch[2500] - loss: 0.201749  batch_size:32\n",
      "Batch[3000] - loss: 0.124170  batch_size:32\n",
      "Batch[3500] - loss: 0.065780  batch_size:32\n",
      "Batch[4000] - loss: 0.168060  batch_size:32\n",
      "Batch[4500] - loss: 0.062048  batch_size:32\n",
      "Average loss:0.160253 \n",
      "5561it [03:31, 26.26it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195044755750119\tMRR:0.6195044755750119\tP@1:0.4699072773250913\tR1:0.4699072773250913\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "IMPChat(\n",
      "  (word_embedding): Embedding(164617, 200, padding_idx=0)\n",
      "  (selector_transformer): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (linear_word): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (linear_score): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transformer_r): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_rp): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_utt): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_res): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ur): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ru): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (cnn_2d_1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (affine2): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (affine3): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (gru_acc): GRU(200, 300, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (linear1): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (linear2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      "  (affine_out): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_utterances:  torch.Size([177950, 29, 50])\n",
      "X_responses:  torch.Size([177950, 50])\n",
      "INFO:impchat:IMPChat(\n",
      "  (word_embedding): Embedding(164617, 200, padding_idx=0)\n",
      "  (selector_transformer): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (linear_word): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (linear_score): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transformer_r): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_rp): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (relu): ReLU()\n",
      "      (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer_utt): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_res): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ur): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (transformer_ru): TransformerBlock(\n",
      "    (relu): ReLU()\n",
      "    (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (cnn_2d_1): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (maxpooling3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn_2d_4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn_2d_6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (affine2): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (affine3): Linear(in_features=576, out_features=200, bias=True)\n",
      "  (gru_acc): GRU(200, 300, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (linear1): Linear(in_features=200, out_features=300, bias=True)\n",
      "    (linear2): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      "  (affine_out): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "5561it [03:31, 26.31it/s]\n",
      "INFO:impchat:Evaluation Result: \n",
      " MAP:0.6195325733552872\tMRR:0.6195325733552872\tP@1:0.46996347288564205\tR1:0.46996347288564205\tR2:0.6011239112110144\tR5:0.822197246417533\n",
      "use time:  1254.110654147466  min\n"
     ]
    }
   ],
   "source": [
    "!bash exec2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ef777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  9 07:15:30 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    58W / 300W |   4442MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    73W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   57C    P0    75W / 300W |  11207MiB / 16160MiB |     37%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    71W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   253W / 300W |  11571MiB / 16160MiB |     76%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.9.10-cikm2",
   "language": "python",
   "name": "venv-3.9.10-cikm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
